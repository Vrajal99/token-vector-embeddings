{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNSyzoorFKB5NbOY7JyzzcJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vrajal99/token-vector-embeddings/blob/main/vectors_tokens_embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokens vs Vectors vs Embeddings:\n",
        "\n",
        "#### Token :\n",
        "#### Basic Data units/ linguistic units\n",
        "---\n",
        "#### Vectors :\n",
        "#### mathematical framework for m/c processing/ 1-D array of high-dimension size\n",
        "---\n",
        "#### Embeddings:\n",
        "#### special vectors that bring or carry depth & understanding/ tokens with semantic context\n",
        "---\n",
        "Token-> Vectors -> Embeddings\n",
        "---"
      ],
      "metadata": {
        "id": "hVG43CksApDc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9VrBynTKvKiB"
      },
      "outputs": [],
      "source": [
        "# https://thenewstack.io/the-building-blocks-of-llms-vectors-tokens-and-embeddings/\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a vector from a list\n",
        "vector = np.array([1,2,3])\n",
        "print(\"Vector:\", vector)"
      ],
      "metadata": {
        "id": "ucr_2eqgvSqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vector addition\n",
        "\n",
        "vector2 = np.array([4,5,6])\n",
        "sum_vector = vector + vector2\n",
        "print(\"Vector addition:\", sum_vector)"
      ],
      "metadata": {
        "id": "luVWpIPTvi2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scalar multiplication\n",
        "scalar = 2 #Scalar is a quantity\n",
        "scaled_vector= vector * scalar\n",
        "print(\"Scalar multiplication:\", scaled_vector)\n"
      ],
      "metadata": {
        "id": "DpI745RkwMEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**These are based on the transformers module from Hugging Face and Tiktoken from OpenAI.**"
      ],
      "metadata": {
        "id": "DVS-CAK1fCbt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Text is converted into tokens for an open model like Llama 2\n",
        "# from transformers import AutoTokenizer\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# HF_Token need to be obtained from Hugging face\n",
        "model = \"meta-llama/Llama-2-7b-chat-hf\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model,token=\"HF_TOKEN\")\n",
        "\n",
        "text = \"Apple is a fruit\"\n",
        "\n",
        "token = tokenizer.encode(text)\n",
        "print(token)\n",
        "\n",
        "decoded_text = tokenizer.decode(token)\n",
        "print(decoded_text)"
      ],
      "metadata": {
        "id": "Ox-pKuYHTXbY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "sfX5jDhwAbWw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "tokenizer=tiktoken.encoding_for_model(\"gpt-4\")\n",
        "\n",
        "text = \"Apple is a fruit\"\n",
        "\n",
        "token=tokenizer.encode(text)\n",
        "print(token)\n",
        "\n",
        "decoded_text = tokenizer.decode(token)\n",
        "print(decoded_text)"
      ],
      "metadata": {
        "id": "0fLqXwrRdGoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The key takeaway is that tokens are vectors based on a specific tokenizer.**"
      ],
      "metadata": {
        "id": "MEz79dnEdXpi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "sentences = [\"Apple is a fruit\",\"Car is a vehicle\"]\n",
        "\n",
        "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "embeddings = model.encode(sentences)\n",
        "\n",
        "print(len(embeddings[0]))\n",
        "\n",
        "print(embeddings)\n"
      ],
      "metadata": {
        "id": "hQ5jDYdjghwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client=OpenAI(api_key=\"Open_API+key\")\n",
        "\n",
        "sentences = [\"Apple is a fruit\",\"Car is a vehicle\"]\n",
        "model = \"text-embedding-3-small\"\n",
        "\n",
        "embeddings = client.embeddings.create(input=sentences, model=model).data[0].embedding\n",
        "\n",
        "print(len(embeddings))\n",
        "\n",
        "print(embeddings)"
      ],
      "metadata": {
        "id": "Y9aqYkiEspYu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}